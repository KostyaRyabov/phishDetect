{'batch_size': 256, 'decay_steps': 450500, 'init': 'truncated_normal', 'layers': {'BatchNormalization': True, 'activation': 'relu', 'dropout': {'dropout_rate': 0.06905306912148117}, 'next': {'BatchNormalization': False, 'activation': 'softsign', 'dropout': None, 'next': None, 'nodes_count': 111}, 'nodes_count': 416}, 'optimizer': {'learning_rate': 0.5616825935032986, 'type': 'Adadelta'}, 'shuffle': True, 'trainable_BatchNormalization': True, 'trainable_dropouts': True}