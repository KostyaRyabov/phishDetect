{'batch_size': 256, 'decay_steps': 881300, 'init': 'glorot_uniform', 'layers': {'BatchNormalization': False, 'activation': 'elu', 'dropout': {'dropout_rate': 0.2815414457633858}, 'next': {'BatchNormalization': False, 'activation': 'tanh', 'dropout': {'dropout_rate': 0.07318274102374758}, 'next': None, 'nodes_count': 455}, 'nodes_count': 337}, 'optimizer': {'learning_rate': 0.0016777984157381812, 'type': 'Adamax'}, 'shuffle': True, 'trainable_BatchNormalization': True, 'trainable_dropouts': False}