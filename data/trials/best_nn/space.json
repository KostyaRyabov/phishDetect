{
  'batch_size': 64,
  'decay_rate': 1.0,
  'decay_steps': 45,
  'init': 'glorot_normal',
  'layers': {
    'BatchNormalization': True,
    'activation': 'tanh',
    'dropout': {
      'dropout_rate': 0.35
    },
    'next': None,
    'nodes_count': 250
  },
  'learning_rate': 0.03,
  'optimizer': {
    'type': 'Adamax'
  },
  'shuffle': True,
  'trainable_BatchNormalization': True,
  'trainable_dropouts': True
}