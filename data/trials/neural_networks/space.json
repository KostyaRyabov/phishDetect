{'batch_size': 64, 'decay_rate': 0.975, 'decay_steps': 31, 'init': 'glorot_normal', 'layers': {'BatchNormalization': True, 'activation': 'softsign', 'dropout': None, 'next': {'BatchNormalization': False, 'activation': 'elu', 'dropout': {'dropout_rate': 0.375}, 'next': None, 'nodes_count': 455}, 'nodes_count': 490}, 'learning_rate': 0.003, 'optimizer': {'centered': False, 'momentum': 0.1, 'type': 'RMSprop'}, 'shuffle': True, 'trainable_BatchNormalization': True, 'trainable_dropouts': True}